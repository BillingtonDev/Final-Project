{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b96cbe",
   "metadata": {},
   "source": [
    "# **Data 200 - Final Project**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818236dd",
   "metadata": {},
   "source": [
    "Author:  Aryan Jain, Micah Billington, Rupesh Rangwani, Devesh Talreja\n",
    "\n",
    "Date : 8th April, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6703cd",
   "metadata": {},
   "source": [
    "## **Summary Of Contents**\n",
    "\n",
    "### This Final Project contains the following sections :\n",
    "1. Introduction\n",
    "2. Data Retrieval & Cleaning\n",
    "3. Data Preprocessing\n",
    "4. Exploratory Data Analysis (EDA)\n",
    "5. Model Application\n",
    "6. Inference & Prediction\n",
    "7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39a30d",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "<img src=\"Stack_Overflow.png\" width=\"400\" align=\"centre\">\n",
    "\n",
    "- The full notebook and datasets can be found on GitHub: https://github.com/TrueCodee/Final-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37182b72",
   "metadata": {},
   "source": [
    "# 2. Data Retrieval & Data Cleaning\n",
    "\n",
    "### 2.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7199b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c0d44f",
   "metadata": {},
   "source": [
    "### 2.2    Data Retrieval & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('survey_results_public.csv')\n",
    "\n",
    "# Convert 'YearsCode' and 'YearsCodePro' to numeric, handling special cases\n",
    "df['YearsCode'] = pd.to_numeric(df['YearsCode'], errors='coerce', downcast='integer')\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce', downcast='integer')\n",
    "\n",
    "# Categorize 'YearsCodePro' into experience levels\n",
    "def categorize_experience(years):\n",
    "    if pd.isna(years):\n",
    "        return 'Unknown'\n",
    "    elif years <= 2:\n",
    "        return 'Novice'\n",
    "    elif years <= 5:\n",
    "        return 'Intermediate'\n",
    "    elif years <= 10:\n",
    "        return 'Experienced'\n",
    "    else:\n",
    "        return 'Veteran'\n",
    "\n",
    "df['ExperienceLevel'] = df['YearsCodePro'].apply(categorize_experience)\n",
    "\n",
    "# Create binary indicators for programming languages of interest\n",
    "languages_of_interest = ['Python', 'JavaScript','R', 'HTML/CSS', 'SQL', 'Java', 'C#', 'TypeScript', 'C', 'C++']\n",
    "for language in languages_of_interest:\n",
    "    df[language] = df['LanguageHaveWorkedWith'].str.contains(language, na=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e0003",
   "metadata": {},
   "source": [
    "## 3. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ecb232",
   "metadata": {},
   "source": [
    "Age Group Analysis: Calculate Language Usage by Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dedf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of respondents in each age group who use Python and SQL\n",
    "languages_of_interest_ds = ['Python','R','SQL']  # Adjusted list for data science relevant languages\n",
    "\n",
    "age_language_usage = df.groupby('Age')[languages_of_interest_ds].mean().reset_index()\n",
    "\n",
    "# Preparing the data for visualization (long format)\n",
    "age_language_usage_long = pd.melt(age_language_usage, id_vars=['Age'], value_vars=languages_of_interest_ds, \n",
    "                                  var_name='Language', value_name='Usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e906f2",
   "metadata": {},
   "source": [
    "Visualize Language Usage by Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Create the barplot\n",
    "chart = sns.barplot(\n",
    "    x='Age', \n",
    "    y='Usage', \n",
    "    hue='Language', \n",
    "    data=age_language_usage_long,\n",
    "    errorbar=None\n",
    ")\n",
    "\n",
    "# Customize the visual elements\n",
    "chart.set_title('Usage of Python and SQL by Age Group', fontsize=16)\n",
    "chart.set_ylabel('Percentage of Respondents', fontsize=12)\n",
    "chart.set_xlabel('Age Group', fontsize=12)\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(title='Programming Language', fontsize=10)\n",
    "\n",
    "# Adding data labels on top of the bars\n",
    "for p in chart.patches:\n",
    "    # Get the height of the bar\n",
    "    height = p.get_height()\n",
    "    # If height is 0, we don't want to display the label\n",
    "    if height > 0:\n",
    "        chart.annotate(f'{height:.1%}', \n",
    "                       (p.get_x() + p.get_width() / 2., height), \n",
    "                       ha = 'center', va = 'center', \n",
    "                       xytext = (0, 9), \n",
    "                       textcoords = 'offset points', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103f705",
   "metadata": {},
   "source": [
    "## 5. Model Appication\n",
    "\n",
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for users who have worked with Python, R, or SQL\n",
    "df_langs = df[df['LanguageHaveWorkedWith'].str.contains('Python|R|SQL', regex=True, na=False)].copy()\n",
    "\n",
    "# Create binary flags for Python, R, and SQL\n",
    "df_langs['Python'] = df_langs['LanguageHaveWorkedWith'].str.contains('Python', regex=True).astype(int)\n",
    "df_langs['R'] = df_langs['LanguageHaveWorkedWith'].str.contains('R', regex=True).astype(int)\n",
    "df_langs['SQL'] = df_langs['LanguageHaveWorkedWith'].str.contains('SQL', regex=True).astype(int)\n",
    "\n",
    "# Convert 'Age' to string to ensure that the dummy variables are handled correctly\n",
    "df_langs['Age'] = df_langs['Age'].astype(str)\n",
    "\n",
    "# Create dummy variables for the 'Age' groups\n",
    "age_dummies = pd.get_dummies(df_langs['Age'], drop_first=True)\n",
    "\n",
    "# Perform logistic regression for Python usage\n",
    "y_python = df_langs['Python']  # Response variable\n",
    "X_python = age_dummies.astype(float) # Independent variables converted to float\n",
    "X_python = sm.add_constant(X_python) # Add a constant to the model (the intercept)\n",
    "model_python = sm.Logit(y_python, X_python).fit()\n",
    "print(model_python.summary())\n",
    "\n",
    "# Logistic Regression Model for combined usage\n",
    "log_reg_model_combined = LogisticRegression(penalty='l2', C=1.0, solver='liblinear')\n",
    "log_reg_model_combined.fit(X_train_combined, y_train_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbf8aa",
   "metadata": {},
   "source": [
    "## 6. Inference & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ffb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for combined usage\n",
    "y_pred_log_reg_combined = log_reg_model_combined.predict(X_test_combined)\n",
    "y_pred_proba_log_reg_combined = log_reg_model_combined.predict_proba(X_test_combined)[:, 1]\n",
    "\n",
    "# Evaluation for combined usage\n",
    "roc_auc_log_reg_combined = roc_auc_score(y_test_combined, y_pred_proba_log_reg_combined)\n",
    "accuracy_log_reg_combined = accuracy_score(y_test_combined, y_pred_log_reg_combined)\n",
    "report_log_reg_combined = classification_report(y_test_combined, y_pred_log_reg_combined, zero_division=0)\n",
    "\n",
    "print(\"Logistic Regression - Combined Python, R, and SQL usage\")\n",
    "print(\"AUC-ROC:\", roc_auc_log_reg_combined)\n",
    "print(\"Accuracy:\", accuracy_log_reg_combined)\n",
    "print(report_log_reg_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
